{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4]) torch.int64\n",
      "tensor([1, 2, 3, 4]) torch.int64\n",
      "2559443949376\n",
      "2559443949376\n",
      "2559443949376\n",
      "2559443949376\n",
      "2559443949376\n",
      "2559443949384\n",
      "0 1\n",
      "###########################\n",
      "tensor([0, 2, 4])\n",
      "False\n",
      "(2,)\n",
      "(1,)\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(5)  # tensor([0, 1, 2, 3, 4])\n",
    "B = A[1:]          # 对A进行截取获得:tensor([1, 2, 3, 4])\n",
    "print(A, A.dtype)\n",
    "print(B, B.dtype)\n",
    "print(A.storage().data_ptr())\n",
    "print(B.storage().data_ptr())\n",
    "print(A[0].storage().data_ptr())\n",
    "print(B[0].storage().data_ptr())\n",
    "print(A[0].data_ptr())\n",
    "print(B[0].data_ptr())\n",
    "print(A.storage_offset(), B.storage_offset())\n",
    "\n",
    "print(\"###########################\")\n",
    "C=A[::2]\n",
    "print(C)\n",
    "# print(C.storage())\n",
    "print(C.is_contiguous())\n",
    "print(C.stride())\n",
    "print(A.stride())\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472004404400\n",
      "1471880567760\n",
      "###########################\n",
      "1471971443888\n",
      "1471971443896\n"
     ]
    }
   ],
   "source": [
    "# numpy访问存储区的方法\n",
    "a = np.arange(5)  # tensor([0, 1, 2, 3, 4])\n",
    "b = a[2:]         # 对A进行截取获得:tensor([2, 3, 4])\n",
    "\n",
    "print(id(a))\n",
    "print(id(b))\n",
    "print(\"###########################\")\n",
    "# 访问存储区真实的存储的数据\n",
    "print(a.__array_interface__['data'][0])\n",
    "print(b.__array_interface__['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m [1, 2, 3] 2559517717952 140728166588160\n",
      "n    [2, 3] 2559517717056 140728166588192\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "m = [1, 2, 3]\n",
    "print('m', m, id(m), id(m[0]))\n",
    "n = m[1:]\n",
    "print('n   ', n, id(n), id(n[0]))\n",
    "print(id(m[1]) == id(n[0])) \n",
    "# n[0] = 4\n",
    "# print('m', m, id(m), id(m[0]))\n",
    "# print('n   ', n, id(n), id(n[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472003733760\n",
      "1472006607936\n",
      "1471976496384\n",
      "###########################\n",
      "1472043755296\n",
      "1472006586624\n",
      "1471976496384\n",
      "###########################\n",
      "1472043753616\n",
      "1472006673728\n",
      "1471976496384\n"
     ]
    }
   ],
   "source": [
    "# 切片时的神奇现象，论证了为什么不能用id()\n",
    "a = torch.tensor([0,1,2,3])\n",
    "print(id(a[0]))\n",
    "print(id(a[0].storage()))\n",
    "print(a[0].storage().data_ptr())\n",
    "print(\"###########################\")\n",
    "\n",
    "print(id(a[0]))\n",
    "print(id(a[0].storage()))\n",
    "print(a[0].storage().data_ptr())\n",
    "print(\"###########################\")\n",
    "\n",
    "print(id(a[0]))\n",
    "print(id(a[0].storage()))\n",
    "print(a[0].storage().data_ptr())\n",
    "\n",
    "\n",
    "\n",
    "# print(id(a[0])==id(a[0])) #先创建左侧，获取到左侧ID，然后销毁左侧ID；再创建右侧，获取右侧ID，再销毁右侧ID\n",
    "# 不可使用下面的语句，卡了python的id设定的bug\n",
    "# print(id(a[0]) is id(a[0])) #同时创建左右两侧ID，则ID必不可能相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472006088064\n",
      "1472003145344\n",
      "1472003143744\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 知乎上的一个有意思的提问\n",
    "t0 = torch.tensor([1, 2, 3])\n",
    "print(id(t0.storage())) # 2028947247624\n",
    "t1 = t0.view(1, 3)\n",
    "print(id(t0.storage())) # 2028947289032\n",
    "print(id(t1.storage())) # 2028947247624\n",
    "print(id(t0.storage())==id(t1.storage()))# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两个例子，表明了tensor和list对象的差异性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559519448736 2559518210864 2559518210864\n",
      "2559519448736 2559517715328 2559517715328\n",
      "2559517715328\n",
      "2559519537488\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "print(id(a), id(a[0]), id(a[1]))\n",
    "a[1:] = torch.tensor([0, 0])\n",
    "print(id(a), id(a[0]), id(a[1])) # 2257492943160 2257492943320 2257492943320 ←①\n",
    "a0 = a[0]\n",
    "print(id(a0)) # 2257492943320\n",
    "a1 = a[1]\n",
    "print(id(a1)) # 2257492943400 ←②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559517439872 2559383846848 2559517746368\n",
      "[[1, 2], [0, 0]]\n",
      "2559517439872 2559383846848 2559517718720\n",
      "2559383846848\n",
      "2559517718720\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2],[3,4]]\n",
    "print(id(a), id(a[0]), id(a[1])) # 2559517439872 2559383846848 2559517746368\n",
    "a[1:] = [[0, 0]] \n",
    "print(a) # [[1, 2], [0, 0]]\n",
    "print(id(a), id(a[0]), id(a[1])) # 2559517439872 2559383846848 2559517718720\n",
    "\n",
    "a0 = a[0]\n",
    "print(id(a0)) # 2559383846848\n",
    "a1 = a[1]\n",
    "print(id(a1)) # 2559517718720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) torch.int64 2559445325760\n",
      "0\n",
      "0\n",
      "tensor(0) torch.int64 2559445325760\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1)\n",
    "print(a,a.dtype,a.storage().data_ptr())\n",
    "\n",
    "print(a.storage_offset())\n",
    "a-=1\n",
    "# a=a-1\n",
    "# print(a.storage_offset(),b.storage_offset())\n",
    "print(a.storage_offset())\n",
    "print(a,a.dtype,a.storage().data_ptr())\n",
    "# print(b,b.dtype,b.storage().data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "torch.Size([2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,3,3,3))\n",
    "print(a)\n",
    "\n",
    "a-=1\n",
    "a/=2\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b87ae1c415bf879c31e2b7111dedfdde99e7fb6020d8739c335659c250c99311"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
